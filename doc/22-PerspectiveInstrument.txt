/**

\page PerInstr The Perspective Instrument

\section PerIntro Introduction

The PerspectiveInstrument class in SKIRT implements a full perspective view of the simulated model, with arbitrary
placement of the viewport outside or inside the model. For each wavelength the instrument maintains the total
luminosity per pixel for all photon packages arriving from the front; light emitted behind the viewport is ignored. The
instrument does \em not maintain the luminosity fractions caused by various phenomena (such as scattered versus direct
light), nor does it keep track of the integrated luminosity across the viewport.

The perspective instrument is intended mostly for making movies. Each movie frame is generated by a separate
perspective instrument with the appropriate parameters.


\section PerParam Parameters and coordinate systems

\image html PerspectiveInstrument1.png
\image latex PerspectiveInstrument1.png

The following table lists all parameters for the perspective instrument
other than the instrument name, which obviously has no effect on the
perspective transformation. Positions and sizes are specified in the
right-handed <em>world coordinate system</em>, i.e.\ the coordinate
system in which the SKIRT model is defined, using units of length
such as parsec. Usually the model is centered around the origin \f$\mathbf{O}\f$
of the world coordinate system.

<TABLE>
<TR><TD><B>Parameter(s)</B></TD>     <TD><B>Description</B></TD></TR>
<TR><TD>\f$N_{x},N_{y}\f$</TD>       <TD>The number of pixels in the viewport in the local
                                         \f$x\f$ and \f$y\f$ directions</TD></TR>
<TR><TD>\f$S_{x},S_{y}\f$</TD>       <TD>The size (twice the extent) of the viewport in the local \f$x\f$ and
                                         \f$y\f$ directions</TD></TR>
<TR><TD>\f$V_{x},V_{y},V_{z}\f$</TD> <TD>The position of the viewport origin \f$\mathbf{V}\f$</TD></TR>
<TR><TD>\f$C_{x},C_{y},C_{z}\f$</TD> <TD>The crosshair position \f$\mathbf{C}\f$ that determines the orientation
                                         of the viewport's \f$z\f$ axis</TD></TR>
<TR><TD>\f$U_{x},U_{y},U_{z}\f$</TD> <TD>The upwards position \f$\mathbf{U}\f$ that determines the orientation
                                         of the viewport's \f$y\f$ axis</TD></TR>
<TR><TD>\f$F_{e}\f$</TD>             <TD>The focal length that determines the position of the eye</TD></TR>
</TABLE>

The aspect ratio of the viewport is assumed to be the same when calculated
in pixels (\f$N_{y}/N_{x}\f$) or in world size (\f$S_{y}/S_{x}\f$). If not
the perspective transformation will introduce a distortion.

The viewport is placed in the \f$xy\f$ plane of the left-handed <em>viewport
coordinate system</em> (left-handed so that depth increases along the
\f$z\f$-axis). Both the viewport and the coordinate system are centered
around the viewport origin \f$\mathbf{V}\f$. The \f$z\f$ axis is placed
along the crosshair line \f$\mathbf{\overline{VC}}\f$, i.e.\ the line
connecting the viewport origin with the crosshair position, in the
direction of \f$\mathbf{C}\f$. Consequently the viewport is perpendicular
to \f$\overline{\mathbf{VC}}\f$. The \f$y\f$ axis is placed such that it
is parallel with the upwards line \f$\overline{\mathbf{OU}}\f$, i.e.\ the
line connecting the \em world origin with the upwards position,
and in the same direction.

The eye and the origin of the left-handed <em>eye coordinate system </em>
are placed on the crosshair line \f$\overline{\mathbf{VC}}\f$ at a distance
\f$F_{e}\f$ from the viewport origin \f$\mathbf{V}\f$, at the opposite side
from \f$\mathbf{C}\f$. In other words, the eye is behind the viewport
and looks towards the crosshair position through the viewport. The
axes of the eye coordinate system have the same orientation as those
of the viewport coordinate system. The perspective transformation
occurs from the eye to the viewport system.


\section PerDeriv Derived positions and directions

We denote the \em norm of an arbitrary point or vector \f$\mathbf{A}\f$ as
\f[
\left\Vert \mathbf{A}\right\Vert =\sqrt{A_{x}^{2}+A_{y}^{2}+A_{z}^{2}}
\f]
A unit vector in the direction from the crosshair position to the
viewport origin can then be written as
\f[
\mathbf{G}=\frac{\mathbf{V}-\mathbf{C}}{\left\Vert \mathbf{V}-\mathbf{C}\right\Vert }
\f]
and the eye position \f$\mathbf{E}\f$ becomes
\f[
\mathbf{E}=\mathbf{V}+F_{e}\mathbf{G}
\f]
When a peel-off photon package is launched towards the instrument
from position \f$\mathbf{P}\f$, a unit vector with the appropriate direction
is given by
\f[
\mathbf{D}=\frac{\mathbf{E}-\mathbf{P}}{\left\Vert \mathbf{E}-\mathbf{P}\right\Vert }
\f]


\section PerHomog Homogeneous coordinates

We use homogeneous coordinates \f$(x,y,z,w)\f$ with arbitrary scale factor
\f$w\f$. An arbitary point \f$\mathbf{P}=(P_{x},P_{y},P_{z})\f$ can be represented
in homogeneous coordinates as \f$\mathcal{P}=(P_{x},P_{y},P_{z},1)\f$.
An arbitrary direction \f$\mathbf{D}=(D_{x},D_{y},D_{z})\f$ is represented
as a point at infinity \f$\mathcal{D}=(D_{x},D_{y},D_{z},0)\f$.

Vice versa, given the homogeneous coordinates \f$\mathcal{Q}=(Q_{x},Q_{y},Q_{z},Q_{w})\f$,
the corresponding regular coordinates for the point can be retrieved
as \f$\mathbf{Q}=(Q_{x}/Q_{w},Q_{y}/Q_{w},Q_{z}/Q_{w})\f$ provided \f$Q_{w}\neq0\f$.

A homogeneous coordinate transformation can be written as \f$\mathcal{P}'=\mathcal{P}\,\mathcal{T}\f$
where \f$\mathcal{T}\f$ is a \f$4\times4\f$ transformation matrix which
can represent a scaling, rotation, translation, perspective transformation
or any combination thereof; or more explicitly
\f[
\left[\begin{array}{cccc}
x' & y' & z' & w'\end{array}\right]=\left[\begin{array}{cccc}
x & y & z & w\end{array}\right]\left[\begin{array}{cccc}
t_{11} & t_{12} & t_{13} & t_{14}\\
t_{21} & t_{22} & t_{23} & t_{24}\\
t_{31} & t_{32} & t_{33} & t_{34}\\
t_{41} & t_{42} & t_{43} & t_{44}
\end{array}\right]
\f]

Consecutive transformations can be combined into a single transformation
matrix through regular matrix multiplication.


\section PerTrans The instrument transformation

When a peel-off photon package launched from position \f$\mathbf{P}\f$
arrives at the perspective instrument, a single transformation is
applied to find the homogeneous coordinates of the pixel receiving
the photon package's luminosity
\f[
\mathcal{J}=\mathcal{P}\,\mathcal{T}_{\mathrm{tot}}
\f]
where \f$\mathcal{P}=(P_{x},P_{y},P_{z},1)\f$ and \f$\mathcal{T}_{\mathrm{tot}}\f$
represents the composite transformation from world coordinates to
pixel coordinates which will be developed below.

The incoming photon package's luminosity is taken into account only
if the package originated in front of the viewport and if the pixel
indices are both within range (from zero up to the number of pixels
in the relevant direction minus one). The pixel indices can be retrieved
using
\f{eqnarray*}
i & = & \mathrm{floor}(\mathcal{J}_{x}/\mathcal{J}_{w})\\
j & = & \mathrm{floor}(\mathcal{J}_{y}/\mathcal{J}_{w})
\f}
based on the standard mechanism for converting homogeneous to regular
coordinates. The perspective transformation developed below is such
that the distance \f$d\f$ from the launching position \f$\mathbf{P}\f$ to
the the viewport plane is given by
\f[
d=\left|\mathcal{J}_{z}\right|
\f]
and \f$\mathbf{P}\f$ is in front of the viewport if and only if \f$\mathcal{J}_{z}>0\f$.
In this case there is no division by \f$\mathcal{J}_{w}\f$ to avoid distortion
of the distance scale by the perspective transformation.


\subsection PerTransDev Developing the transformation

At the highest level we compose the instrument transformation as follows
\f[
\mathcal{T}_{\mathrm{tot}}=\mathcal{T}_{we}\,\mathcal{T}_{ev}\,\mathcal{T}_{vp}
\f]
where
  - \f$\mathcal{T}_{we}\f$ transforms from world coordinates to eye coordinates
  - \f$\mathcal{T}_{ev}\f$ transforms from eye coordinates to viewport coordinates
  - \f$\mathcal{T}_{vp}\f$ transforms from viewport coordinates to pixel coordinates


\subsection PerTransWtE From world to eye coordinates

The transformation from world to eye coordinates can be composed as
follows
\f[
\mathcal{T}_{we}=\mathcal{M}_{e}\,\mathcal{R}_{xy}\,\mathcal{R}_{z}\,\mathcal{F}_{z}
\f]
with from left to right:
  - translate the origin to the eye position;
  - rotate around the \f$x\f$ and \f$y\f$ axes to align the \f$z\f$ axis with the
    crosshair line \f$\overline{\mathbf{CV}}\f$, pointing in the direction
    of the eye; the \f$xy\f$ plane is now parallel with the viewport;
  - rotate around the \f$z\f$ axis to align the \f$y\f$ axis so that it is parallel
    with and in the same direction as the projection on the \f$xy\f$ plane
    of the upwards line \f$\overline{\mathbf{OU}}\f$; the \f$y\f$ axis now points
    up and the \f$x\f$ axis now points to the right when looking down from
    the positive \f$z\f$ axis;
  - flip the direction of the \f$z\f$ axis so that depth increases away from the eye.

It is easy to see that
\f[
\mathcal{M}_{e}=\left[\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
-E_{x} & -E_{y} & -E_{z} & 1
\end{array}\right]\qquad\mathrm{and}\qquad\mathcal{F}_{z}=\left[\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & -1 & 0\\
0 & 0 & 0 & 1
\end{array}\right]
\f]

To determine \f$\mathcal{R}_{xy}\f$ let \f$(a,b,c)\f$ be the direction cosines
of the desired \f$z\f$ axis alignment, i.e.\ the direction \f$\mathbf{G}\f$
from the crosshair position to the eye position
\f[
(a,b,c)=(G_{x},G_{y},G_{z})
\f]
and define \f$v=\sqrt{b^{2}+c^{2}}\f$ as the
hypothenuse of the direction vector's projection in the \f$yz\f$ plane.
For the time being, assume that \f$v\neq0\f$.

\image html PerspectiveInstrument2.png
\image latex PerspectiveInstrument2.png

Alignment of the \f$z\f$ axis with \f$(a,b,c)\f$ can then be accomplished
by a rotation over \f$\alpha\f$ about the \f$x\f$ axis (figure (a)) followed
by a rotation over \f$\beta\f$ about the \f$y\f$ axis (figure (b)) -- the
angles are directed clockwise when looking down from the positive
rotation axis. The projection of vector \f$(a,b,c)\f$ in the \f$yz\f$ plane
has components \f$b\f$ along the \f$y\f$ axis and \f$c\f$ along the \f$z\f$ axis,
so that \f$\cos\alpha=c/v\f$ and \f$\sin\alpha=-b/v\f$. The situation after
the first rotation is shown in figure (b). The length of the hypothenuse
in this figure is \f$1\f$ since the direction cosines \f$(a,b,c)\f$ are
normalized. It is then immediately clear that \f$\cos\beta=v\f$ and \f$\sin\beta=-a\f$.
Thus we find
\f[
\mathcal{R}_{xy}=\left[\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & {c}/{v} & {b}/{v} & 0\\
0 & -\,{b}/{v} & {c}/{v} & 0\\
0 & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{cccc}
v & 0 & a & 0\\
0 & 1 & 0 & 0\\
-a & 0 & v & 0\\
0 & 0 & 0 & 1
\end{array}\right]
\f]

To determine \f$\mathcal{R}_{z}\f$, let \f$(k,l,m)\f$ be the direction cosines
of the desired \f$y\f$ axis alignment, i.e.\ the direction from the
world origin to the upwards position, \em after partial transformation
to eye coordinates
\f[
\left[\begin{array}{cccc}
k & l & m & 1\end{array}\right]=\left[\begin{array}{cccc}
U_{x} & U_{y} & U_{z} & 1\end{array}\right]\,\mathcal{R}_{xy}
\f]
so that the projection of the upwards direction on the eye \f$xy\f$ plane
has components \f$k\f$ along the \f$x\f$ axis and \f$l\f$ along the \f$y\f$ axis.
Using the previously derived value for \f$\mathcal{R}_{xy}\f$ simple
matrix algebra leads to
\f[
k=(b^{2}+c^{2})U_{x}-abU_{y}-acU_{z}\qquad\mathrm{and}\qquad l=cU_{y}-bU_{z}
\f]
where we dropped a proportionality factor of \f$1/v\f$ in both values,
since \f$k\f$ and \f$l\f$ are not normalized.

\image html PerspectiveInstrument3.png
\image latex PerspectiveInstrument3.png

We need a rotation over \f$\gamma\f$ about the \f$z\f$ axis (figure (c)).
Defining \f$u=\sqrt{k^{2}+l^{2}}\f$, a reasoning
similar to the one before gives \f$\cos\gamma=l/u\f$ and \f$\sin\gamma=-k/u\f$,
and thus
\f[
\mathcal{R}_{z}=\left[\begin{array}{cccc}
{l}/{u} & {k}/{u} & 0 & 0\\
-\,{k}/{u} & {l}/{u} & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}\right]
\f]

In case \f$v\approx0\f$ the matrices \f$\mathcal{R}_{xy}\f$ and \f$\mathcal{R}_{z}\f$
as derived above are not well defined and the rotations to align the
\f$z\f$ axis should be performed in reverse order, i.e. first about the
\f$y\f$ axis and then about the \f$x\f$ axis. A reasoning similar to the
above leads to the alternative
\f[
v'=\sqrt{a^{2}+c^{2}}
\f]
\f[
\mathcal{R}'_{xy}=\left[\begin{array}{cccc}
{c}/{v'} & 0 & {a}/{v'} & 0\\
0 & 1 & 0 & 0\\
-\,{a}/{v'} & 0 & {c}/{v'} & 0\\
0 & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & v' & b & 0\\
0 & -b & v' & 0\\
0 & 0 & 0 & 1
\end{array}\right]
\f]
\f[
k'=cU_{x}-aU_{z}
\f]
\f[
l'=(a^{2}+c^{2})U_{y}-abU_{x}-bcU_{z}
\f]
\f[
u'=\sqrt{k'^{2}+l'^{2}}
\f]
\f[
\mathcal{R}'_{z}=\left[\begin{array}{cccc}
{l'}/{u'} & {k'}/{u'} & 0 & 0\\
-\,{k'}/{u'} & {l'}/{u'} & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}\right]
\f]


\subsection PerTransEtV From eye to viewport coordinates

\image html PerspectiveInstrument4.png
\image latex PerspectiveInstrument4.png

The figure shows the \f$yz\f$ plane of the eye and viewport coordinate
systems. To develop the perspective transformation, note that the
triangles \f$EP'V\f$ and \f$EPQ\f$ are similar so that \f$\frac{y_{v}}{F_{e}}=\frac{y_{e}}{z_{e}}\f$.
With similar reasoning in the \f$xz\f$ plane, we get
\f{eqnarray*}
x_{v} & = & F_{e}\frac{x_{e}}{z_{e}}\\
y_{v} & = & F_{e}\frac{y_{e}}{z_{e}}
\f}
In the \f$z\f$ direction we wish to preserve the distance scale and simply
perform the translation
\f[
z_{v}=z_{e}-F_{e}
\f]

This can be accomplished through the homogeneous transformation matrix
\f[
\mathcal{T}_{ev}=\left[\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 1/F_{e}\\
0 & 0 & -F_{e} & 0
\end{array}\right]
\f]
keeping in mind that the \f$x_{v}\f$ and \f$y_{v}\f$ coordinates will be
divided by \f$w_{v}=z_{e}/F_{e}\f$ when converting from homogeneous to
regular coordinates, and assuming that the \f$z_{v}\f$ coordinate will
not be divided by this factor. This ``trick'' for the \f$z\f$ coordinate
works only because we have set \f$w=1\f$ when converting the original
point to homogeneous coordinates, and none of the other transformation
matrices change the \f$w\f$ coordinate.


\subsection PerTransVtP From viewport to pixel coordinates

The viewport is centered on the origin and is scaled in world distances,
while pixel indices range from zero to the number of pixels in each
direction minus one. Thus we need to apply the following scaling and
translation
\f[
\mathcal{T}_{vp}=\left[\begin{array}{cccc}
{N_{x}}/{S_{x}} & 0 & 0 & 0\\
0 & {N_{y}}/{S_{y}} & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
{N_{x}}/{2} & {N_{y}}/{2} & 0 & 1
\end{array}\right]
\f]

We leave the depth coordinate unchanged, which means it is still scaled
in world distances, zero depth corresponds with the viewport plane,
and positive depth indicates positions in front of the viewport.


\section PerFlux Flux calibration

Each photon package arriving at the instrument carries a certain fraction
of luminosity \f$L_{\lambda}\f$ at a particular wavelength
\f$\lambda\f$. The contribution of the photon package to the surface
brightness \f$S_{\lambda}\f$ of the instrument pixel being hit can be
written as
\f[
S_{\lambda}=\frac{\lambda}{\Delta\lambda}\frac{1}{4\pi d^{2}}\frac{1}{\Omega}L_{\lambda}
\f]
where \f$\Delta\lambda\f$ is the width of the wavelength bin corresponding
to \f$\lambda\f$, \f$d\f$ is the distance from the photon package's origin
to the instrument, and \f$\Omega\f$ is the solid angle that spans the
area of a single pixel at a distance \f$d\f$, i.e.
\f[
\Omega=2\arctan\left(\frac{1}{2}\frac{S_{x}/N_{x}}{d}\right)\times2\arctan\left(\frac{1}{2}\frac{S_{y}/N_{y}}{d}\right)
\f]
Assuming that the instrument pixels are square, i.e.\ the aspect
ratio of the viewport is the same when calculated in pixels (\f$N_{y}/N_{x}\f$)
or in world size (\f$S_{y}/S_{x}\f$), we can express the width of a pixel
as
\f[
s=\frac{S_{x}}{N_{x}}=\frac{S_{y}}{N_{y}}
\f]
so that
\f[
\Omega=4\arctan^{2}\!\left(\frac{s}{2d}\right)
\f]


For large distances \f$d\gg s\f$ we can use \f$\arctan x\approx x\f$ when
\f$x\ll1\f$ to obtain \f$\Omega\approx s^{2}/d^{2}\f$ so that
\f[
S_{\lambda,\gg}=\frac{\lambda}{\Delta\lambda}\frac{1}{4\pi s^{2}}L_{\lambda}\qquad(d\gg s)
\f]
which is independent of the actual distance. For smaller distances
this approximation doesn't hold and the surface brightness can be
written in terms of \f$S_{\lambda,\gg}\f$ and a correction factor
\f[
S_{\lambda}=\frac{\left(\frac{s}{2d}\right)^{2}}{\arctan^{2}\!\left(\frac{s}{2d}\right)}\: S_{\lambda,\gg}
\f]


The following table lists the correction factor for a few values of
\f$d/s\f$.

<TABLE>
<TR><TD><B>Distance</B></TD>        <TD><B>Correction factor</B></TD></TR>
<TR><TD>\f$d=\frac{1}{50}s\f$</TD>  <TD>\f$266.7\f$</TD></TR>
<TR><TD>\f$d=\frac{1}{10}s\f$</TD>  <TD>\f$13.25\f$</TD></TR>
<TR><TD>\f$d=\frac{1}{4}s\f$</TD>   <TD>\f$3.263\f$</TD></TR>
<TR><TD>\f$d=\frac{1}{2}s\f$</TD>   <TD>\f$1.621\f$</TD></TR>
<TR><TD>\f$d=s\f$</TD>              <TD>\f$1.163\f$</TD></TR>
<TR><TD>\f$d=10\, s\f$</TD>         <TD>\f$1.0017\f$</TD></TR>
<TR><TD>\f$d=100\, s\f$</TD>        <TD>\f$1.000017\f$</TD></TR>
</TABLE>

To avoid overly large contributions from extremely nearby objects,
it seems reasonable to ignore any photon packages that originated
too close to the viewport, for example with \f$d<\frac{1}{10}s\f$.

*/
